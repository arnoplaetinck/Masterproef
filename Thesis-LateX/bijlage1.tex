\chapter{Benchmark code}

\section{Runnen benchmark}
\begin{lstlisting}
from numpy import genfromtxt
import pyrenn as prn
import csv
import time
from statistics import mean
import psutil
from PIL import Image
import tensorflow as tf
import numpy as np
import gzip

import nvidia_smi

nvidia_smi.nvmlInit()
handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)
# card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate
res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))

cores = []
cpu_percent = []
virtual_mem = []
time_start = []
time_stop = []

time_total = 0
iterations = 2
labels = ["compair", "friction", "narendra4", "pt2", "P0Y0_narendra4", "P0Y0_compair", "gradient",
"FashionMNIST", "NumberMNIST", "catsVSdogs", "Im Rec", "Totaal"]

###
# Creating a filename
seconds = time.time()
local_time = time.ctime(seconds)
naam2 = local_time.split()
naam = "Benchmark_PC"
for i in range(len(naam2)):
naam += "_" + naam2[i]
naam = naam.replace(':', '_')

with open('./logging/' + naam + ".csv", mode='w') as results_file:
fieldnames = ['Naam', 'CPU Percentage', 'timediff']
file_writer = csv.DictWriter(results_file, fieldnames=fieldnames)
file_writer.writeheader()


def logging_data(program_index, stop, start, cpu):
# Logging data
cores_avg = mean(cpu)
time_diff = stop-start

with open('./logging/' + naam + ".csv", mode='a+') as data_file:
data_writer = csv.DictWriter(data_file, fieldnames=fieldnames)
data_writer.writerow(
{'Naam': labels[program_index],
	'CPU Percentage': str(cores_avg),
	'timediff': str(time_diff)
})


# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# first time calling cpu percent to get rid of 0,0
psutil.cpu_percent(interval=None, percpu=True)

# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# example_compair.py
# This is an example of a dynamic system with 2 outputs and 3 inputs
print("compair")
iteration = 0
while iteration < iterations:
# Read Example Data
df = genfromtxt('example_data_compressed_air.csv', delimiter=',')
df = df.transpose()

P = np.array([df[1][1:-1], df[2][1:-1], df[3][1:-1]])
Y = np.array([df[4][1:-1], df[5][1:-1]])
Ptest = np.array([df[6][1:-1], df[7][1:-1], df[8][1:-1]])
Ytest = np.array([df[9][1:-1], df[10][1:-1]])

# Load saved NN from file
net = prn.loadNN("./SavedNN/compair.csv")

psutil.cpu_percent(interval=None, percpu=True)
time_start = time.time()

# Calculate outputs of the trained NN for train and test data
y = prn.NNOut(P, net)
ytest = prn.NNOut(Ptest, net)

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

time_stop = (time.time())
cores = psutil.cpu_percent(interval=None, percpu=True)
if (mean(cores) != 0.0) and (time_stop-time_start != 0):
logging_data(0, time_stop, time_start, cores)
iteration += 1
time_total += time_stop - time_start
print("iteration: ", iteration, " mean cores: ", mean(cores), " time_stop-time_start: ", time_stop-time_start)

# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# example_friction.py
print("friction")
iteration = 0
while iteration < iterations:    # Read Example Data
df = genfromtxt('example_data_friction.csv', delimiter=',')
df = df.transpose()

P = df[1][1:-1]
Y = df[2][1:-1]
Ptest = df[3][1:-1]
Ytest = df[4][1:-1]

# Load saved NN from file
net = prn.loadNN("./SavedNN/friction.csv")

psutil.cpu_percent(interval=None, percpu=True)
time_start = time.time()

# Calculate outputs of the trained NN for train and test data
y = prn.NNOut(P, net)
ytest = prn.NNOut(Ptest, net)

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

time_stop = (time.time())
cores = psutil.cpu_percent(interval=None, percpu=True)
if (mean(cores) != 0.0) and (time_stop-time_start != 0):
logging_data(1, time_stop, time_start, cores)
iteration += 1
time_total += time_stop - time_start
print("iteration: ", iteration, " mean cores: ", mean(cores), " time_stop-time_start: ", time_stop-time_start)
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# example_narendra4.py
print("narendra4")
iteration = 0
while iteration < iterations:
# Read Example Data
df = genfromtxt('example_data_narendra4.csv', delimiter=',')
df = df.transpose()

P = df[1][1:-1]
Y = df[2][1:-1]
Ptest = df[3][1:-1]
Ytest = df[4][1:-1]

# Load saved NN from file
net = prn.loadNN("./SavedNN/narendra4.csv")

psutil.cpu_percent(interval=None, percpu=True)
time_start = time.time()

# Calculate outputs of the trained NN for train and test data
y = prn.NNOut(P, net)
ytest = prn.NNOut(Ptest, net)

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

time_stop = (time.time())
cores = psutil.cpu_percent(interval=None, percpu=True)
if (mean(cores) != 0.0) and (time_stop-time_start != 0):
logging_data(2, time_stop, time_start, cores)
iteration += 1
time_total += time_stop - time_start
print("iteration: ", iteration, " mean cores: ", mean(cores), " time_stop-time_start: ", time_stop-time_start)
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# example_pt2.py
print("pt2")
iteration = 0
while iteration < iterations:
# Read Example Data
df = genfromtxt('example_data_friction.csv', delimiter=',')
df = df.transpose()

P = df[1][1:-1]
Y = df[2][1:-1]
Ptest = df[3][1:-1]
Ytest = df[4][1:-1]

# Load saved NN from file
net = prn.loadNN("./SavedNN/pt2.csv")

psutil.cpu_percent(interval=None, percpu=True)
time_start = time.time()

# Calculate outputs of the trained NN for train and test data
y = prn.NNOut(P, net)
ytest = prn.NNOut(Ptest, net)

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

time_stop = (time.time())
cores = psutil.cpu_percent(interval=None, percpu=True)
if (mean(cores) != 0.0) and (time_stop-time_start != 0):
logging_data(3, time_stop, time_start, cores)
iteration += 1
time_total += time_stop - time_start
print("iteration: ", iteration, " mean cores: ", mean(cores), " time_stop-time_start: ", time_stop-time_start)
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# example_using_P0Y0_narendra4.py
print("using_P0Y0_narendra4")
iteration = 0
while iteration < iterations:
# Read Example Data
df = genfromtxt('example_data_narendra4.csv', delimiter=',')
df = df.transpose()

P = df[1][1:-1]
Y = df[2][1:-1]
Ptest = df[3][1:-1]
Ytest = df[4][1:-1]

# define the first 3 timesteps t=[0,1,2] of Test Data as previous (known) data P0test and Y0test
P0test = Ptest[0:3]
Y0test = Ytest[0:3]
# Use the timesteps t = [3..99] as Test Data
Ptest = Ptest[3:100]
Ytest = Ytest[3:100]

# Load saved NN from file
net = prn.loadNN("./SavedNN/using_P0Y0_narendra4.csv")

psutil.cpu_percent(interval=None, percpu=True)
time_start = time.time()

# Calculate outputs of the trained NN for test data with and without previous input P0 and output Y0
ytest = prn.NNOut(Ptest, net)
y0test = prn.NNOut(Ptest, net, P0=P0test, Y0=Y0test)

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

time_stop = (time.time())
cores = psutil.cpu_percent(interval=None, percpu=True)
if (mean(cores) != 0.0) and (time_stop-time_start != 0):
logging_data(4, time_stop, time_start, cores)
iteration += 1
time_total += time_stop - time_start
print("iteration: ", iteration, " mean cores: ", mean(cores), " time_stop-time_start: ", time_stop-time_start)
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# example_gradient.py
print("gradient")

iteration = 0
while iteration < iterations:
df = genfromtxt('example_data_pt2.csv', delimiter=',')
df = df.transpose()

P = df[1][1:-1]
Y = df[2][1:-1]

# Load saved NN from file
net = prn.loadNN("./SavedNN/gradient.csv")

psutil.cpu_percent(interval=None, percpu=True)
time_start = time.time()

# Prepare input Data for gradient calculation
data, net = prn.prepare_data(P, Y, net)

# Real Time Recurrent Learning
J, E, e = prn.RTRL(net, data)
g_rtrl = 2 * np.dot(J.transpose(), e)  # calculate g from Jacobian and error vector

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

time_stop = (time.time())
cores = psutil.cpu_percent(interval=None, percpu=True)
if (mean(cores) != 0.0) and (time_stop-time_start != 0):
logging_data(6, time_stop, time_start, cores)
iteration += 1
time_total += time_stop - time_start
print("iteration: ", iteration, " mean cores: ", mean(cores), " time_stop-time_start: ", time_stop-time_start)

# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# FashionMNISTREAD.py
print("Fashion MNISTREAD")

f = gzip.open('./datasets/fashionMNIST/t10k-images-idx3-ubyte.gz', 'r')
image_size = 28
num_images = 10_000
f.read(16)
buf = f.read(image_size * image_size * num_images)
data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)
data = data.reshape(num_images, image_size, image_size)
f.close()

f = gzip.open('./datasets/fashionMNIST/t10k-labels-idx1-ubyte.gz', 'r')
f.read(8)
test_labels = []
for i in range(0, 10_000):
buf = f.read(1)
inhoud = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)
test_labels.append(inhoud)
f.close()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'coat',
'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
path_model = "./SavedNN/FashionMNIST/fashionMNISTmodel.tflite"

# Data Preprocessing
test_images = data / 255

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=path_model)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Get input and output shapes
floating_model = input_details[0]['dtype'] == np.float32
height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]

# Test model on  input data.
input_shape = input_details[0]['shape']

# Preprocessing data 2
index = 0
input_data_array = []

for image in test_images:
input_data = np.expand_dims(test_images[index], axis=0)
index += 1
if floating_model:
input_data = np.float32(input_data)
input_data_array.append(input_data)

iteration = 0
while iteration < iterations:
output_data_array = []

psutil.cpu_percent(interval=None, percpu=True)
time_start = time.time()

for index in range(10000):
interpreter.set_tensor(input_details[0]['index'], input_data_array[index])
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
output_data_array.append(output_data)

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

time_stop = (time.time())
cores = psutil.cpu_percent(interval=None, percpu=True)
if (mean(cores) != 0.0) and (time_stop-time_start != 0):
logging_data(7, time_stop, time_start, cores)
iteration += 1
time_total += time_stop - time_start
print("iteration: ", iteration, " mean cores: ", mean(cores), " time_stop-time_start: ", time_stop-time_start)

# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# NumberMNISTREAD.py
print("NumberMNISTREAD")

f = gzip.open('./datasets/numberMNIST/t10k-images-idx3-ubyte.gz', 'r')
image_size = 28
num_images = 10_000
f.read(16)
buf = f.read(image_size * image_size * num_images)
data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)
data = data.reshape(num_images, image_size, image_size)
f.close()

f = gzip.open('./datasets/numberMNIST/t10k-labels-idx1-ubyte.gz', 'r')
f.read(8)
test_labels = []
for i in range(0, 10_000):
buf = f.read(1)
label = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)
test_labels.append(label)
f.close()

class_names = ["zero", "one", "two", "three", "four", "five", "six", "seven", "eight", "nine"]
path_model = "./SavedNN/NumberMNIST/mnist_model.tflite"

# Data Preprocessing
test_images = data / 255

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=path_model)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Get input and output shapes
floating_model = input_details[0]['dtype'] == np.float32
height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]

# Test model on  input data.
input_shape = input_details[0]['shape']

# Preprocessing data 2
index = 0
input_data_array = []
for image in test_images:
input_data = np.expand_dims(test_images[index], axis=0)
index += 1
if floating_model:
input_data = np.float32(input_data)
input_data_array.append(input_data)

iteration = 0
while iteration < iterations:
output_data_array = []

psutil.cpu_percent(interval=None, percpu=True)
time_start = time.time()

for index in range(10_000):
interpreter.set_tensor(input_details[0]['index'], input_data_array[index])
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
output_data_array.append(output_data)

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

time_stop = time.time()
cores = psutil.cpu_percent(interval=None, percpu=True)
if (mean(cores) != 0.0) and (time_stop-time_start != 0):
logging_data(8, time_stop, time_start, cores)
iteration += 1
time_total += time_stop - time_start
print("iteration: ", iteration, " mean cores: ", mean(cores), " time_stop-time_start: ", time_stop-time_start)

# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# catsVSdogs10Read.py
# 124 images from COCO val2017 dataset
print("catsVSdogs10Read")

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
'dog', 'frog', 'horse', 'ship', 'truck']
path_image = "./images/catsVSdogs/"
extention = ".jpg"
path_model = "./SavedNN/catsVSdogs/"
labels_array = np.arange(0, 39)
# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=path_model + "catsVSdogsmodel.tflite")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test model on  input data.
input_shape = input_details[0]['shape']
floating_model = input_details[0]['dtype'] == np.float32
height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]
print(height, width)
input_data2 = []

for label in labels_array:
path = path_image + "/Cat/" + str(label) + extention
img = Image.open(path).resize((width, height))

input_data = np.expand_dims(img, axis=0)
if floating_model:
input_data = (np.float32(input_data)) / 255
input_data2.append(input_data)
for label in labels_array:
path = path_image + "/Dog/" + str(label) + extention
img = Image.open(path).resize((width, height))
# img.show()
img.save("./images/test/" + str(label) + ".png")
input_data = np.expand_dims(img, axis=0)

if floating_model:
input_data = (np.float32(input_data)) / 255
input_data2.append(input_data)


iteration = 0
while iteration < iterations:
psutil.cpu_percent(interval=None, percpu=True)
time_start = time.time()

for data in input_data2:
interpreter.set_tensor(input_details[0]['index'], data)

interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
npa = np.asarray(output_data[0], dtype=np.float32)
# print(class_names[np.argmax(npa)])

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

time_stop = (time.time())
cores = psutil.cpu_percent(interval=None, percpu=True)
if (mean(cores) != 0.0) and (time_stop-time_start != 0):
logging_data(9, time_stop, time_start, cores)
iteration += 1
time_total += time_stop - time_start
print("iteration: ", iteration, " mean cores: ", mean(cores), " time_stop-time_start: ", time_stop-time_start)

# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# ImRecKerasRead.py
# 124 images from COCO val2017 dataset
print("ImRecKerasRead")

path_image = "./images/KerasRead/"
extention = ".jpg"

imagenet_labels = np.array(open(path_image+"ImageNetLabels.txt").read().splitlines())

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path="./SavedNN/ImRecKerasModel/ImRecKerasModel.tflite")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

floating_model = input_details[0]['dtype'] == np.float32
height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]
print("height: ", height, " width", width)

input_data2 = []
with open("./images/KerasRead/labels.txt", mode='r') as label_file:
for label in label_file:
path = path_image + label.rstrip() + extention
img = Image.open(path).resize((width, height))
input_data = np.expand_dims(img, axis=0)
if floating_model:
input_data = (np.float32(input_data) - 127.5) / 127.5
input_data2.append(input_data)

iteration = 0
while iteration < iterations:
psutil.cpu_percent(interval=None, percpu=True)
time_start = time.time()

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

for data in input_data2:
interpreter.set_tensor(input_details[0]['index'], data)

interpreter.invoke()
res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')
output_data = interpreter.get_tensor(output_details[0]['index'])

decoded = imagenet_labels[np.argsort(output_data)[0, ::-1][:5] + 1]
print("Result AFTER saving: ", decoded)

res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')

time_stop = (time.time())
cores = psutil.cpu_percent(interval=None, percpu=True)
if (mean(cores) != 0.0) and (time_stop-time_start != 0):
logging_data(10, time_stop, time_start, cores)
iteration += 1
time_total += time_stop - time_start
print("iteration: ", iteration, " mean cores: ", mean(cores), " time_stop-time_start: ", time_stop-time_start)

cores = psutil.cpu_percent(interval=2, percpu=True)
with open('./logging/' + naam + ".csv", mode='a+') as data_file:
data_writer = csv.DictWriter(data_file, fieldnames=fieldnames)

data_writer.writerow(
{'Naam': labels[-1],
	'CPU Percentage': str(mean(cores)),
	'timediff': str(time_total/iterations)
})
\end{lstlisting}











\newpage
\section{Plotten resultaten} \label{sec:bijlageplotresults}

\begin{lstlisting}
import csv
from statistics import mean
import matplotlib.pyplot as plt
import numpy as np
from tabulate import tabulate

iterations = 20
boxplot_bool = False

name_PC = "Benchmark_PC_Thu_Apr_2_22_05_01_2020"
name_PI = "Benchmark_PI_Fri_Apr_3_02_32_27_2020"
name_NANO = "Benchmark_NANO_Fri_Apr_3_02_11_17_2020"
name_CORAL = "Benchmark_CORAL_Wed_Apr_3_20_08_16_2020"

file_names = [name_PC, name_PI, name_NANO, name_CORAL]

data_CPU = [[], [], [], []]
data_time = [[], [], [], []]
data_CPU_avg = [[], [], [], []]
data_time_avg = [[], [], [], []]

cpu_percent = []
virtual_mem = []
time_diff = []

programs = ["compair", "friction", "narendra4", "pt2", "P0Y0_narendra4",
			"gradient", "FashionMNIST", "NumberMNIST", "catsVSdogs", "Im Rec"]
labels_cpu = programs + ["no operations"]
labels_time = programs + ["Total*"]

ylabel_time = 'Time program execution during running'
ylabel_cpu = 'CPU usage during running'
title_time = 'Time program execution for each device during running'
title_cpu = 'CPU usage for each device during running'

devices = ["PC", "PI", "NANO", "CORAL"]
clockspeed = [3.25, 1.2, 1.479, 1.5]
device_price = [981, 41.5, 99, 149.99]
power = [79.9, 3.7, 5, 2.65]

width = 0.22
image_path = "./images/figures/"


def show_plot(data, ylabel, titel, labels, log, show, index, boxplot, normalise):
	if not show:
		return
	
	def autolabel(rects):
		"""Attach a text label above each bar in *rects*, displaying its height."""
		for rect in rects:
			height = rect.get_height()
			ax.annotate('{}'.format(height),
						xy=(rect.get_x() + rect.get_width() / 2, height),
						xytext=(0, 3),  # 3 points vertical offset
						textcoords="offset points",
						ha='center', va='bottom')
		
	data_bar = [[], [], [], []]
	for device in range(len(devices)):
		for program in range(len(labels)):
			data_bar[device].append(float(round(mean(data[device][program]), 3)))
			for iteration in range(iterations):
				data[device][program][iteration] = round(data[device][program][iteration], 5)
	fig, ax = plt.subplots()
	
	# the label locations
	x = np.arange(len(labels))
	
	# variables to be used for broken PC normalised line
	xmin = x - 3 * width / 2
	xmax = x + 3 * width / 2
	y = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
	
	if not normalise:
		rects1 = ax.bar(x - 3 * width / 2, data_bar[1], width, label='PI', color='lightgreen')
		rects2 = ax.bar(x - width / 2, data_bar[2], width, label='NANO', color='limegreen')
		rects3 = ax.bar(x + width / 2, data_bar[3], width, label='CORAL', color='green')
		rects4 = ax.bar(x + 3 * width / 2, data_bar[0], width, label='PC', color='lightblue')
		autolabel(rects1)
		autolabel(rects2)
		autolabel(rects3)
		autolabel(rects4)
		if boxplot:
			ax.boxplot(data[1], positions=x - 3 * width / 2, widths=width, showfliers=True)
			ax.boxplot(data[2], positions=x - width / 2, widths=width, showfliers=True)
			ax.boxplot(data[3], positions=x + width / 2, widths=width, showfliers=True)
			ax.boxplot(data[0], positions=x + 3 * width / 2, widths=width, showfliers=True)
	elif normalise:
		rects2 = ax.bar(x - width, data_bar[1], width, label='PI', color='lightgreen')
		rects3 = ax.bar(x, data_bar[2], width, label='NANO', color='limegreen')
		rects4 = ax.bar(x + width, data_bar[3], width, label='CORAL', color='green')
	
		autolabel(rects2)
		autolabel(rects3)
		autolabel(rects4)
	
		ax.hlines(y=1,
		xmin=xmin[0],
		xmax=xmax[-1],
		colors='r', linestyles='solid', label='PC')
		if boxplot:
			ax.boxplot(data[1], positions=x - width, widths=width)
			ax.boxplot(data[2], positions=x, widths=width)
			ax.boxplot(data[3], positions=x + width, widths=width)
		
	# Add some text for labels, title and custom x-axis tick labels, etc.
	ax.set_ylabel(ylabel, fontsize=15)
	ax.set_title(titel, fontsize=15)
	ax.set_xticks(x)
	ax.set_xticklabels(labels)
	plt.xticks(rotation=45)
	ax.legend(prop={'size': 20})
	
	fig.tight_layout()
	plt.grid()
	ax.set_axisbelow(True)
	mng = plt.get_current_fig_manager()
	mng.window.state('zoomed')
	if log:
		plt.yscale("log")
	plt.savefig(image_path + "Figure_{}".format(index))
	plt.show()


def tabel(data):
	table = [["PC"], ["PI"], ["NANO"], ["CORAL"]]
	
	for program in range(len(programs)):
		for device in range(len(devices)):
			table[device].append(round(mean(data[device][program]), 3))
	print()
	print(tabulate(table, headers=["Device", "compair", "friction", "narendra4", "pt2", "P0Y0_narendra4",
	"P0Y0_compair", "gradient", "FashionMNIST", "NumberMNIST", "catsVSdogs", "Im Rec"]))
	print()


# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Data extraction
for device in range(len(file_names)):
	temp1, temp2, = [], []
	
	with open('./logging/' + file_names[device] + ".csv", mode='r') as results_file:
		results_reader = csv.DictReader(results_file)
		for row in results_reader:
			temp2.append(float(row['timediff']))
			temp1.append(float(row['CPU Percentage']) / 100)
	
	for program in range(len(programs)):
		time_diff_avg = round(mean(temp2[program * iterations:(program * iterations + iterations)]), 5)
		cpu_avg = round(mean(temp1[program * iterations:(program * iterations + iterations)]), 5)
		data_CPU_avg[device].append(cpu_avg)
		data_time_avg[device].append(time_diff_avg)
	
		data_CPU[device].append(temp1[program * iterations:(program * iterations + iterations)])
		data_time[device].append(temp2[program * iterations:(program * iterations + iterations)])
	data_CPU[device].append([])
	data_time[device].append([])
	
	for iteration in range(iterations):
		data_CPU[device][-1].append(temp1[-1])
		data_time[device][-1].append(temp2[-1])
	data_CPU_avg[device].append(temp1[-1])
	data_time_avg[device].append(temp2[-1])

# Adding new total value to PI
total = 0
for program in range(len(programs)-1):
	total += mean(data_time[1][program])
data_time[1][-1] = []
for iteration in range(iterations):
	data_time[1][-1].append(total)

# Plotting figures
show_plot(data_time, ylabel_time, title_time, labels_time, log=True, show=True, index=0, boxplot=boxplot_bool, normalise=False)
show_plot(data_CPU, ylabel_cpu, title_cpu, labels_cpu, log=False, show=True, index=1, boxplot=boxplot_bool, normalise=False)

# making sure variables have right shape, content of data_time will be ignored
data_time_norm = []
data_energy = []
data_energy_norm = []
data_time_MHzCPU = []
data_time_MHzCPU_norm = []
data_time_MHzCPUprice = []
data_time_MHzCPUprice_norm = []

for device in range(len(devices)):
	data_time_norm.append([])
	data_energy.append([])
	data_energy_norm.append([])
	data_time_MHzCPU.append([])
	data_time_MHzCPU_norm.append([])
	data_time_MHzCPUprice.append([])
	data_time_MHzCPUprice_norm.append([])
	
	for program in range(len(labels_time)):
		data_time_norm[device].append([])
		data_energy[device].append([])
		data_energy_norm[device].append([])
		data_time_MHzCPU[device].append([])
		data_time_MHzCPU_norm[device].append([])
		data_time_MHzCPUprice[device].append([])
		data_time_MHzCPUprice_norm[device].append([])
		
		for iteration in range(iterations):
			data_time_norm[device][program].append([])
			data_energy[device][program].append([])
			data_energy_norm[device][program].append([])
			data_time_MHzCPU[device][program].append([])
			data_time_MHzCPU_norm[device][program].append([])
			data_time_MHzCPUprice[device][program].append([])
			data_time_MHzCPUprice_norm[device][program].append([])

# Rescaling to lowest nr of each program
pc_values = []
for program in range(len(labels_time)):
	pc_values.append(mean(data_time[0][program]))
	for device in range(len(devices)):
		for iteration in range(iterations):
			data_time_norm[device][program][iteration] = \
				data_time[device][program][iteration] / pc_values[program]

show_plot(data=data_time_norm,
			ylabel=ylabel_time,
			titel=title_time + ", Normalised",
			labels=labels_time,
			log=True, show=True, index=2,
			boxplot=boxplot_bool, normalise=True)

# plotting time/MHz/cpu%
for device in range(len(devices)):
	for program in range(len(labels_time)):
		for iteration in range(iterations):
			data_time_MHzCPU[device][program][iteration] = \
				data_time[device][program][iteration] / clockspeed[device] / data_CPU_avg[device][program]

show_plot(data=data_time_MHzCPU,
			ylabel="Time / CPU% / MHz.",
			titel="Time / CPU% / MHz for each device.",
			labels=labels_time,
			log=True, show=False, index=3,
			boxplot=boxplot_bool, normalise=False)

# plotting normalised time/MHz/cpu%
pc_values = []
for label in range(len(labels_time)):
	pc_values.append(mean(data_time_MHzCPU[0][label]))

for device in range(len(devices)):
	for program in range(len(labels_time)):
		for iteration in range(iterations):
			data_time_MHzCPU_norm[device][program][iteration] = data_time_MHzCPU[device][program][iteration] / 		pc_values[program]
			
show_plot(data_time_MHzCPU_norm,
			ylabel="Time / CPU% / MHz.",
			titel="Time / CPU% / MHz for each device, Normalised.",
			labels=labels_time,
			log=True, show=False, index=4,
			boxplot=boxplot_bool, normalise=True)

# plotting time*watt
for device in range(len(devices)):
	for program in range(len(labels_time)):
		for iteration in range(iterations):
			data_energy[device][program][iteration] = \
				power[device] * data_time[device][program][iteration]

show_plot(data=data_energy,
			ylabel="Time * Watt.",
			titel="Time * Watt for each device.",
			labels=labels_time,
			log=True, show=False, index=5,
			boxplot=boxplot_bool, normalise=False)

# plotting normalised time/watt
pc_values = []
for label in range(len(labels_time)):
	pc_values.append(mean(data_energy[0][label]))

for device in range(len(devices)):
	for program in range(len(labels_time)):
		for iteration in range(iterations):
			data_energy_norm[device][program][iteration] = data_energy[device][program][iteration] / pc_values[program]
			
show_plot(data_energy_norm,
			ylabel="Time * Watt.",
			titel="Time * Watt, Normalised.",
			labels=labels_time,
			log=True, show=False, index=6,
			boxplot=boxplot_bool, normalise=True)

# plotting time/$
for device in range(len(devices)):
	for program in range(len(labels_time)):
		for iteration in range(iterations):
			data_time_MHzCPUprice[device][program][iteration] = device_price[device] / data_time[device][program][iteration]

show_plot(data=data_time_MHzCPUprice,
			ylabel="Time * dollar.",
			titel="Time * dollar for each device.",
			labels=labels_time,
			log=True, show=True, index=7,
			boxplot=boxplot_bool, normalise=False)

# plotting normalised time/MHz/cpu%/$
pc_values = []
for label in range(len(labels_time)):
	pc_values.append(mean(data_time_MHzCPUprice[0][label]))

for device in range(len(devices)):
	for program in range(len(labels_time)):
		for iteration in range(iterations):
			data_time_MHzCPUprice_norm[device][program][iteration] = data_time_MHzCPUprice[device][program][iteration] / pc_values[program]
			
show_plot(data=data_time_MHzCPUprice_norm,
			ylabel="Time * dollar.",
			titel="Time * dollar for each device, Normalised.",
			labels=labels_time,
			log=True, show=True, index=8,
			boxplot=boxplot_bool, normalise=True)

tabel(data_time)
tabel(data_time_norm)
tabel(data_time_MHzCPU)
tabel(data_time_MHzCPU_norm)
tabel(data_time_MHzCPUprice)
tabel(data_time_MHzCPUprice_norm)
\end{lstlisting}